{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b790aa-d477-433b-81d2-3191ffc98f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data: 403 Client Error: Forbidden for url: https://api.linkedin.com/v2/shares?q=owners&owners=urn:li:organization:YOUR_ORGANIZATION_ID&sortBy=LAST_MODIFIED&sharesPerOwner=100\n",
      "No posts data available for organization YOUR_ORGANIZATION_ID.\n",
      "No posts found for this organization.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import psycopg2\n",
    "import psycopg2.extras  # Import the extras module\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "month_ago = int(time.mktime((datetime.now() - timedelta(days=29)).timetuple()))\n",
    "\n",
    "ACCESS_TOKEN = 'ppp'\n",
    "\n",
    "# Base URL for the Facebook Graph API\n",
    "BASE_URL = \"https://graph.facebook.com/v20.0/\"\n",
    "\n",
    "#id is account_id and also page_id DATAFRAME NAME = fb_accounts\n",
    "f_accounts = \"me/accounts?fields=id,access_token,username,name,profile_picture_url,email,biography,description,followers_count,follows_count,website,media_count&access_token={}\".format(ACCESS_TOKEN)\n",
    "\n",
    "\n",
    "def fetch_api_data(url):\n",
    "    all_data = []\n",
    "    try:\n",
    "        while url:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()  # Will raise an HTTPError for bad responses\n",
    "            result = response.json()\n",
    "            \n",
    "            if 'data' in result:\n",
    "                all_data.extend(result['data'])\n",
    "\n",
    "            if 'paging' in result and 'next' in result['paging']:\n",
    "                url = result['paging']['next']\n",
    "            else:\n",
    "                url = None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "    return all_data\n",
    "\n",
    "# Fetch account data\n",
    "accounts_url = f\"{BASE_URL}{f_accounts}\"\n",
    "\n",
    "# Fetch the accounts data\n",
    "fb_accounts_data = fetch_api_data(accounts_url)\n",
    "\n",
    "# Convert the fetched data to a DataFrame\n",
    "fb_accounts = pd.DataFrame(fb_accounts_data)\n",
    "\n",
    "\n",
    "# Loop through accounts and fetch page insights for each\n",
    "\n",
    "fb_page_insights_data = []\n",
    "\n",
    "for index, row in fb_accounts.iterrows():\n",
    "    page_id = row['id']  # Use the page_id from fb_accounts\n",
    "    page_token = row['access_token']  # Use the page access token\n",
    "    \n",
    "    # Define f_page_insights INSIDE the loop with the correct page_id and page_token\n",
    "    f_page_insights = \"{page_id}/insights?metric=page_impressions,page_impressions_unique,page_fan_adds,page_fan_removes,page_fans_online,page_fans_country,page_fans_city,page_views_total,page_post_engagements,page_total_actions,page_consumptions_by_consumption_type,page_negative_feedback,page_negative_feedback_unique,page_posts_impressions,page_posts_impressions_unique,page_posts_impressions_paid,page_posts_impressions_organic,page_post_engagements&access_token={PAGE_TOKEN}&period=day&since={month_ago}\".format(page_id=page_id, PAGE_TOKEN=page_token, month_ago=month_ago)\n",
    "    \n",
    "    # Build the URL for fetching page insights\n",
    "    page_insights_url = f\"{BASE_URL}{f_page_insights}\"\n",
    "\n",
    "    # Fetch the data\n",
    "    insights_data = fetch_api_data(page_insights_url)\n",
    "\n",
    "    # Dictionary to hold combined metrics for the current page and date\n",
    "    insights_combined = {}\n",
    "\n",
    "    # Loop through each metric in the insights_data\n",
    "    for insight in insights_data:\n",
    "        metric_name = insight['name']\n",
    "        for value in insight['values']:\n",
    "            end_time = value['end_time']\n",
    "            \n",
    "            # If this end_time isn't already in the combined data, initialize it\n",
    "            if end_time not in insights_combined:\n",
    "                insights_combined[end_time] = {\n",
    "                    'page_id': page_id,\n",
    "                    'end_date': end_time\n",
    "                }\n",
    "\n",
    "            # Add the metric to the corresponding end_time dictionary\n",
    "            insights_combined[end_time][metric_name] = value['value']\n",
    "\n",
    "    # Convert combined metrics into rows for the DataFrame\n",
    "    for end_time, combined_row in insights_combined.items():\n",
    "        fb_page_insights_data.append(combined_row)\n",
    "\n",
    "# Convert the insights data to a DataFrame\n",
    "fb_page_insights = pd.DataFrame(fb_page_insights_data)\n",
    "\n",
    "\n",
    "\n",
    "# Loop through accounts and fetch page posts for each\n",
    "fb_posts_data = []\n",
    "\n",
    "for index, row in fb_accounts.iterrows():\n",
    "    page_id = row['id']  # Use the page_id from fb_accounts\n",
    "    page_token = row['access_token']  # Use the page access token\n",
    "    \n",
    "    # Define f_posts INSIDE the loop with the correct page_id and page_token\n",
    "    f_posts = \"{page_id}/posts?fields=id,parent_id,promotion_status,scheduled_publish_time,message,message_tags,created_time,permalink_url,status_type,call_to_action,instagram_eligibility,is_published,is_hidden,ad_status,ads_run&access_token={PAGE_TOKEN}\".format(page_id=page_id, PAGE_TOKEN=page_token)\n",
    "    \n",
    "    # Build the URL for fetching posts\n",
    "    posts_url = f\"{BASE_URL}{f_posts}\"\n",
    "\n",
    "    # Fetch the data\n",
    "    posts_data = fetch_api_data(posts_url)\n",
    "\n",
    "    # Loop through the posts in the 'posts' list\n",
    "    for post in posts_data:\n",
    "        fb_posts_data.append({\n",
    "            'page_id': page_id,  # Save the page_id (account_id)\n",
    "            'page_token': page_token,  # Save the page token\n",
    "            'post_id': post['id'],\n",
    "            'parent_id': post.get('parent_id', None),\n",
    "            'promotion_status': post.get('promotion_status', None),\n",
    "            'scheduled_publish_time': post.get('scheduled_publish_time', None),\n",
    "            'message': post.get('message', None),\n",
    "            'message_tags': json.dumps(post.get('message_tags', None)),  # Serialize JSON tags if available\n",
    "            'created_time': post.get('created_time', None),\n",
    "            'permalink_url': post.get('permalink_url', None),\n",
    "            'status_type': post.get('status_type', None),\n",
    "            'call_to_action': json.dumps(post.get('call_to_action', None)),  # Serialize JSON call_to_action if available\n",
    "            'instagram_eligibility': post.get('instagram_eligibility', None),\n",
    "            'is_published': post.get('is_published', None),\n",
    "            'is_hidden': post.get('is_hidden', None),\n",
    "            'ad_status': post.get('ad_status', None),\n",
    "            'ads_run': post.get('ads_run', None)\n",
    "        })\n",
    "\n",
    "# Convert the flattened posts data to a DataFrame\n",
    "fb_posts = pd.DataFrame(fb_posts_data)\n",
    "\n",
    "\n",
    "# Loop through posts and fetch post insights for each\n",
    "fb_post_insight_data = []\n",
    "\n",
    "for index, row in fb_posts.iterrows():\n",
    "    post_id = row['post_id']  # Extract the post_id from the current row\n",
    "    page_id = row['page_id']  # Extract the page_id from the current row\n",
    "    \n",
    "    # Retrieve the page_token from the current row (if not already available)\n",
    "    page_token = row['page_token']\n",
    "    \n",
    "    # Define f_post_insight INSIDE the loop with the correct post_id and page_token\n",
    "    f_post_insight = \"{post_id}/insights?metric=post_impressions,post_clicks,post_impressions_paid,post_activity_by_action_type,post_clicks_by_type,page_consumptions_by_consumption_type&access_token={PAGE_TOKEN}&period=day&since={month_ago}\".format(post_id=post_id, PAGE_TOKEN=page_token, month_ago=month_ago)\n",
    "    \n",
    "    # Build the URL for fetching post insights\n",
    "    post_insight_url = f\"{BASE_URL}{f_post_insight}\"\n",
    "\n",
    "    # Fetch the data\n",
    "    post_insight_data = fetch_api_data(post_insight_url)\n",
    "\n",
    "    # Dictionary to hold combined metrics for the current post and date\n",
    "    post_insights_combined = {}\n",
    "\n",
    "    # Loop through each metric in the post_insight_data\n",
    "    for insight in post_insight_data:\n",
    "        metric_name = insight['name']\n",
    "        for value in insight['values']:\n",
    "            end_time = value['end_time']\n",
    "            \n",
    "            # If this end_time isn't already in the combined data, initialize it\n",
    "            if end_time not in post_insights_combined:\n",
    "                post_insights_combined[end_time] = {\n",
    "                    'post_id': post_id,\n",
    "                    'page_id': page_id,\n",
    "                    'end_date': end_time\n",
    "                }\n",
    "\n",
    "            # Add the metric to the corresponding end_time dictionary\n",
    "            post_insights_combined[end_time][metric_name] = value['value']\n",
    "\n",
    "    # Convert combined metrics into rows for the DataFrame\n",
    "    for end_time, combined_row in post_insights_combined.items():\n",
    "        fb_post_insight_data.append(combined_row)\n",
    "\n",
    "# Convert the insights data to a DataFrame\n",
    "fb_post_insights = pd.DataFrame(fb_post_insight_data)\n",
    "\n",
    "\n",
    "# Loop through posts and fetch post comments for each\n",
    "fb_post_comments_data = []\n",
    "\n",
    "for index, row in fb_posts.iterrows():\n",
    "    post_id = row['post_id']  # Extract the post_id from the current row\n",
    "    page_id = row['page_id']  # Extract the page_id from the current row\n",
    "    \n",
    "    # Retrieve the page_token from the current row (if not already available)\n",
    "    page_token = row['page_token']\n",
    "        \n",
    "    # Define f_post_comments INSIDE the loop with the correct post_id and page_token\n",
    "    f_post_comments = \"{post_id}/comments?fields=from,id,message,created_time,like_count,comment_count,attachment,parent,hidden&access_token={PAGE_TOKEN}\".format(post_id=post_id, PAGE_TOKEN=page_token)\n",
    "        \n",
    "    # Build the URL for fetching post comments\n",
    "    post_comments_url = f\"{BASE_URL}{f_post_comments}\"\n",
    "\n",
    "    # Fetch the data\n",
    "    post_comments_data = fetch_api_data(post_comments_url)\n",
    "\n",
    "    # Loop through each comment in the fetched data\n",
    "    for comment in post_comments_data:\n",
    "        from_user = comment.get('from', {}).get('name')  # Extract 'from' field's name\n",
    "        comment_id = comment['id']  # Comment ID\n",
    "        message = comment.get('message')  # Message content\n",
    "        created_time = comment.get('created_time')  # Creation time of the comment\n",
    "        like_count = comment.get('like_count', 0)  # Number of likes on the comment\n",
    "        comment_count = comment.get('comment_count', 0)  # Number of replies to the comment\n",
    "        attachment = json.dumps(comment.get('attachment', {}))  # Serialize attachment to JSON\n",
    "        parent = comment.get('parent', {}).get('id')  # Parent comment if this is a reply\n",
    "        hidden = comment.get('hidden', False)  # Whether the comment is hidden\n",
    "\n",
    "        # Append flattened data to the fb_post_comments_data list\n",
    "        fb_post_comments_data.append({\n",
    "            'post_id': post_id,\n",
    "            'page_token': page_token,  # Save the page token            \n",
    "            'comment_id': comment_id,\n",
    "            'from_user': from_user,\n",
    "            'message': message,\n",
    "            'created_time': created_time,\n",
    "            'like_count': like_count,\n",
    "            'comment_count': comment_count,\n",
    "            'attachment': attachment,\n",
    "            'parent': parent,\n",
    "            'hidden': hidden\n",
    "        })\n",
    "\n",
    "# Convert the flattened post comments data to a DataFrame\n",
    "fb_post_comments = pd.DataFrame(fb_post_comments_data)\n",
    "\n",
    "\n",
    "fb_comments_data = []\n",
    "\n",
    "for index, row in fb_post_comments.iterrows():\n",
    "    comment_id = comment['id']  # Extract the comment_id from the comment data\n",
    "    post_id = row['post_id']  # Extract the post_id from the current row\n",
    "\n",
    "    # Retrieve the page_token from the current row\n",
    "    page_token = row['page_token']\n",
    "\n",
    "    # Define f_comments INSIDE the loop with the correct comment_id and page_token\n",
    "    f_comments = \"{comment_id}/comments?fields=from,id,message,created_time,like_count,attachment,parent,hidden&access_token={PAGE_TOKEN}\".format(comment_id=comment_id, PAGE_TOKEN=page_token)\n",
    "\n",
    "    # Build the URL for fetching comment replies\n",
    "    comments_url = f\"{BASE_URL}{f_comments}\"\n",
    "\n",
    "    # Fetch the data\n",
    "    comments_data = fetch_api_data(comments_url)\n",
    "\n",
    "    # Loop through replies to the comment\n",
    "    for reply in comments_data:\n",
    "        reply_id = reply['id']  # Extract the reply_id\n",
    "        from_user = reply.get('from', {}).get('name')  # Extract the name of the user\n",
    "        message = reply.get('message')  # Extract the message content\n",
    "        created_time = reply.get('created_time')  # Extract the creation time\n",
    "        like_count = reply.get('like_count', 0)  # Number of likes on the reply\n",
    "        attachment = json.dumps(reply.get('attachment', {}))  # Serialize the attachment field\n",
    "        parent_comment = reply.get('parent', {}).get('id')  # Parent comment ID, if this is a reply\n",
    "        hidden = reply.get('hidden', False)  # Whether the reply is hidden\n",
    "            \n",
    "        # Append flattened reply data to the fb_comments_data list\n",
    "        fb_comments_data.append({\n",
    "            'post_id': post_id,\n",
    "            'comment_id': comment_id,\n",
    "            'reply_id': reply_id,\n",
    "            'from_user': from_user,\n",
    "            'message': message,\n",
    "            'created_time': created_time,\n",
    "            'like_count': like_count,\n",
    "            'attachment': attachment,\n",
    "            'parent_comment': parent_comment,\n",
    "            'hidden': hidden\n",
    "        })\n",
    "\n",
    "# Convert the comments data (with replies) to a DataFrame\n",
    "fb_comments = pd.DataFrame(fb_comments_data)\n",
    "\n",
    "\n",
    "# Loop through comments and fetch reactions for each\n",
    "fb_reactions_data = []\n",
    "\n",
    "for index, row in fb_post_comments.iterrows():\n",
    "    comment_id = comment['id']  # Extract the comment_id from the comment data\n",
    "    post_id = row['post_id']  # Extract the post_id from the current row\n",
    "\n",
    "    # Retrieve the page_token from the current row\n",
    "    page_token = row['page_token']\n",
    "\n",
    "    # Define f_reactions INSIDE the loop with the correct comment_id and page_token\n",
    "    f_reactions = \"{comment_id}/reactions?fields=id,name,type&access_token={PAGE_TOKEN}\".format(comment_id=comment_id, PAGE_TOKEN=page_token)\n",
    "\n",
    "    # Build the URL for fetching reactions\n",
    "    reactions_url = f\"{BASE_URL}{f_reactions}\"\n",
    "\n",
    "    # Fetch the data\n",
    "    reactions_data = fetch_api_data(reactions_url)\n",
    "\n",
    "    # Flatten the reactions data if multiple reactions exist\n",
    "    for reaction in reactions_data:\n",
    "        reaction_id = reaction.get('id')  # Reaction ID\n",
    "        name = reaction.get('name')  # Reaction user name\n",
    "        type_ = reaction.get('type')  # Reaction type (like, love, etc.)\n",
    "\n",
    "        # Append the reaction data to fb_reactions_data list\n",
    "        fb_reactions_data.append({\n",
    "             'post_id': post_id,  # Save the post_id\n",
    "            'comment_id': comment_id,  # Save the comment_id\n",
    "            'reaction_id': reaction_id,  # Reaction ID\n",
    "            'name': name,  # Name of the user who reacted\n",
    "            'type': type_  # Type of reaction\n",
    "        })\n",
    "\n",
    "# Convert the reactions data to a DataFrame\n",
    "fb_reactions = pd.DataFrame(fb_reactions_data)\n",
    "\n",
    "\n",
    "# Loop through accounts and fetch page cta for each\n",
    "fb_cta_data = []\n",
    "\n",
    "for index, row in fb_accounts.iterrows():\n",
    "    page_id = row['id']  # Use the page_id from fb_accounts\n",
    "    page_token = row['access_token']  # Use the page access token\n",
    "    \n",
    "    # Define the correct query for fetching CTA fields\n",
    "    f_cta = \"{page_id}/call_to_actions?fields=id,type,status,web_url,mobile_url,created_time,updated_time&access_token={PAGE_TOKEN}\".format(page_id=page_id, PAGE_TOKEN=page_token)\n",
    "    \n",
    "    # Build the URL for fetching CTA data\n",
    "    cta_url = f\"{BASE_URL}{f_cta}\"\n",
    "\n",
    "    # Fetch the data\n",
    "    cta_data = fetch_api_data(cta_url)\n",
    "\n",
    "    # Unpack the CTA data into individual columns\n",
    "    for cta in cta_data:\n",
    "        fb_cta_data.append({\n",
    "            'page_id': page_id,            # Save the page_id\n",
    "            'cta_id': cta.get('id'),       # Save the CTA id\n",
    "            'type': cta.get('type'),   # Save the CTA type\n",
    "            'status': cta.get('status'),  # Save the CTA status\n",
    "            'web_url': cta.get('web_url'), # Save the CTA web_url\n",
    "            'mobile_url': cta.get('mobile_url'), # Save the mobile_url\n",
    "            'created_time': cta.get('created_time'), # Save the created time\n",
    "            'updated_time': cta.get('updated_time')  # Save the updated time\n",
    "        })\n",
    "\n",
    "# Convert the CTA data to a DataFrame with separate columns for each field\n",
    "fb_cta = pd.DataFrame(fb_cta_data)\n",
    "\n",
    "\n",
    "# Database connection settings\n",
    "DB_SETTINGS = {\n",
    "    'dbname': 'postgres',\n",
    "    'user': 'XXX',\n",
    "    'password': 'YYYY!',\n",
    "    'host': 'ZZZZ',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "def upsert_data_into_table(dataframe, table_name, column_mapping, conflict_columns, batch_size=500):\n",
    "    dataframe = dataframe.replace({np.nan: None})\n",
    "    data_tuples = []\n",
    "\n",
    "    # Prepare data tuples for insertion, including handling of JSON fields and timestamp\n",
    "    for row in dataframe.to_dict(orient='records'):\n",
    "        formatted_row = []\n",
    "        for df_col, db_col in column_mapping.items():\n",
    "            value = row.get(df_col)\n",
    "            if isinstance(value, dict):  # Handle JSONB fields\n",
    "                formatted_row.append(json.dumps(value))  # Serialize JSON fields\n",
    "            else:\n",
    "                formatted_row.append(value)  # Non-JSON fields\n",
    "        # Add the current datetime for updated_at\n",
    "        formatted_row.append(datetime.now())\n",
    "        data_tuples.append(tuple(formatted_row))\n",
    "\n",
    "    # Prepare the conflict columns for ON CONFLICT clause\n",
    "    conflict_column_str = ', '.join(conflict_columns)\n",
    "\n",
    "    # Exclude updated_at from being overwritten, but handle other columns\n",
    "    update_columns = [f\"{db_col} = EXCLUDED.{db_col}\" for db_col in column_mapping.values() if db_col != 'updated_at' and db_col not in conflict_columns]\n",
    "\n",
    "    # SQL query for upsert\n",
    "    insert_query = f\"\"\"\n",
    "    INSERT INTO {table_name} ({', '.join(column_mapping.values())}, updated_at) \n",
    "    VALUES %s\n",
    "    ON CONFLICT ({conflict_column_str}) \n",
    "    DO UPDATE SET {', '.join(update_columns)}, updated_at = NOW()\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute the query in batches\n",
    "    try:\n",
    "        with psycopg2.connect(**DB_SETTINGS) as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                for batch_start in range(0, len(data_tuples), batch_size):\n",
    "                    batch = data_tuples[batch_start:batch_start + batch_size]\n",
    "                    psycopg2.extras.execute_values(cur, insert_query, batch)\n",
    "            conn.commit()\n",
    "    except Exception as e:\n",
    "        print(f\"Error during upsert: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "accounts_mapping = {\n",
    "        'id': 'account_id',\n",
    "        'username': 'username',\n",
    "        'name': 'name',\n",
    "        'profile_picture_url': 'profile_picture_url',\n",
    "        'email': 'email',\n",
    "        'biography': 'biography',\n",
    "        'description': 'description',\n",
    "        'followers_count': 'followers_count',\n",
    "        'follows_count': 'follows_count',\n",
    "        'website': 'website',\n",
    "        'media_count': 'media_count'\n",
    "}\n",
    "\n",
    "comments_mapping = {\n",
    "        'comment_id': 'comment_id',\n",
    "        'reply_id': 'reply_id',\n",
    "        'from_user': 'from_user',\n",
    "        'message': 'message',\n",
    "        'created_time': 'created_time',\n",
    "        'like_count': 'like_count',\n",
    "        'attachment': 'attachment',\n",
    "        'parent': 'parent',\n",
    "        'hidden': 'hidden'\n",
    "}\n",
    "\n",
    "page_cta_mapping = {\n",
    "        'page_id': 'account_id',\n",
    "        'cta_id': 'cta_id',\n",
    "        'type': 'type',\n",
    "        'status': 'status',\n",
    "        'web_url': 'web_url',\n",
    "        'mobile_url': 'mobile_url',\n",
    "        'created_time': 'created_time',\n",
    "        'updated_time': 'updated_time'\n",
    "}\n",
    "\n",
    "page_insights_mapping = {\n",
    "        'page_id': 'account_id',\n",
    "        'end_date': 'end_date',\n",
    "        'page_impressions': 'page_impressions',\n",
    "        'page_impressions_unique': 'page_impressions_unique',\n",
    "        'page_fan_adds': 'page_fan_adds',\n",
    "        'page_fan_removes': 'page_fan_removes',\n",
    "        'page_fans_online': 'page_fans_online',\n",
    "        'page_fans_country': 'page_fans_country',\n",
    "        'page_fans_city': 'page_fans_city',\n",
    "        'page_views_total': 'page_views_total',\n",
    "        'page_post_engagements': 'page_post_engagements',\n",
    "        'page_total_actions': 'page_total_actions',\n",
    "        'page_consumptions_by_consumption_type': 'page_consumptions_by_consumption_type',\n",
    "        'page_negative_feedback': 'page_negative_feedback',\n",
    "        'page_negative_feedback_unique': 'page_negative_feedback_unique',\n",
    "        'page_posts_impressions': 'page_posts_impressions',\n",
    "        'page_posts_impressions_unique': 'page_posts_impressions_unique',\n",
    "        'page_posts_impressions_paid': 'page_posts_impressions_paid',\n",
    "        'page_posts_impressions_organic': 'page_posts_impressions_organic',\n",
    "        'period': 'period'\n",
    "}\n",
    "\n",
    "post_comments_mapping = {\n",
    "        'post_id': 'post_id',\n",
    "        'comment_id': 'comment_id',\n",
    "        'from_user': 'from_user',\n",
    "        'message': 'message',\n",
    "        'created_time': 'created_time',\n",
    "        'like_count': 'like_count',\n",
    "        'comment_count': 'comment_count',\n",
    "        'attachment': 'attachment',\n",
    "        'parent': 'parent',\n",
    "        'hidden': 'hidden'\n",
    "}\n",
    "\n",
    "post_insights_mapping = {\n",
    "        'post_id': 'post_id',\n",
    "        'account_id': 'account_id',\n",
    "        'end_date': 'end_date',\n",
    "        'post_impressions': 'post_impressions',\n",
    "        'post_clicks': 'post_clicks',\n",
    "        'post_impressions_paid': 'post_impressions_paid',\n",
    "        'post_activity_by_action_type': 'post_activity_by_action_type',\n",
    "        'post_clicks_by_type': 'post_clicks_by_type',\n",
    "        'page_consumptions_by_consumption_type': 'page_consumptions_by_consumption_type',\n",
    "        'period': 'period'\n",
    "}\n",
    "\n",
    "posts_mapping = {\n",
    "        'post_id': 'post_id',\n",
    "        'page_id': 'account_id',\n",
    "        'promotion_status': 'promotion_status',\n",
    "        'scheduled_publish_time': 'scheduled_publish_time',\n",
    "        'message': 'message',\n",
    "        'message_tags': 'message_tags',\n",
    "        'created_time': 'created_time',\n",
    "        'permalink_url': 'permalink_url',\n",
    "        'status_type': 'status_type',\n",
    "        'call_to_action': 'call_to_action',\n",
    "        'instagram_eligibility': 'instagram_eligibility',\n",
    "        'is_published': 'is_published',\n",
    "        'is_hidden': 'is_hidden',\n",
    "        'ad_status': 'ad_status',\n",
    "        'ads_run': 'ads_run'\n",
    "}\n",
    "\n",
    "reactions_mapping = {\n",
    "    'comment_id': 'comment_id',\n",
    "    'reaction_id': 'reaction_id',\n",
    "    'name': 'name',\n",
    "    'type': 'type'\n",
    "}\n",
    "\n",
    "\n",
    "#fb_accounts, 'fb.accounts', accounts_mapping, conflict_columns=['account_id']\n",
    "#fb_page_insights, 'fb.page_insights', page_insights_mapping, conflict_columns=['account_id','end_date']\n",
    "#fb_posts, 'fb.posts', posts_mapping, conflict_columns=['post_id']\n",
    "#fb_post_insight, 'fb.post_insights', post_insights_mapping, conflict_columns=['post_id','end_date']\n",
    "#fb_post_comments, 'fb.post_comments', comments_mapping, conflict_columns=['post_id', 'comment_id','created_time']\n",
    "#fb_comments, 'fb.comments', comments_mapping, conflict_columns = ['comment_id','created_time']\n",
    "#fb_reactions, 'fb_reactions', reactions_mapping, conflict_columns = ['reaction_id']\n",
    "#fb_cta, 'fb.page_cta', page_cta_mapping, conflict_columns - ['cta_id']\n",
    "\n",
    "upsert_data_into_table(fb_accounts, 'fb.accounts', accounts_mapping, conflict_columns=['account_id'])\n",
    "upsert_data_into_table(fb_page_insights, 'fb.page_insights', page_insights_mapping, conflict_columns=['account_id','end_date'])\n",
    "upsert_data_into_table(fb_posts, 'fb.posts', posts_mapping, conflict_columns=['post_id'])\n",
    "upsert_data_into_table(fb_post_insights, 'fb.post_insights', post_insights_mapping, conflict_columns=['post_id','end_date'])\n",
    "upsert_data_into_table(fb_post_comments, 'fb.post_comments', post_comments_mapping, conflict_columns=['post_id', 'comment_id','created_time'])\n",
    "upsert_data_into_table(fb_comments, 'fb.comments', comments_mapping, conflict_columns = ['comment_id', 'reply_id','created_time'])\n",
    "upsert_data_into_table(fb_reactions, 'fb.reactions', reactions_mapping, conflict_columns = ['reaction_id'])\n",
    "upsert_data_into_table(fb_cta, 'fb.page_cta', page_cta_mapping, conflict_columns = ['cta_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7328686-bab2-4786-b5f9-0a9b2f2da6eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
